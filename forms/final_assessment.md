# Learning Machine Learning: Test Your Knowledge
Welcome to the final step of our journey! Here, you will solve questions that are related to the topics that you have learned for the past weeks. This is not an assessment, and you will receive no penalties for your scores. If you are not sure about how to solve a question, choose "Not sure"; please do not refer to any external resource or try to guess an answer. You will solve 15 multiple choice questions, and at the end we prepared some questions for you to tell us about your experience during the learning program. Thank you for your time and cooperation in this study, and good luck!

### 1. Enter the same id you used for the math test. If you did not write it down, it was of the following format: Your favorite color + favorite dessert + favorite animal. (e.g. Orange Stroopwafel Cat)

Your answer here

### 2. What is your current degree program?
- Computer science and Engineering
- Industrial Design
- Applied Mathematics
- Aerospace Engineering
- Applied Physics
- Electrical Engineering
- Other

### 3. Why do we split data into training and test sets in a machine learning pipeline?
- To evaluate the model’s performance on unseen data. V
- To improve the speed of the model.
- To reduce the size of the dataset.
- To optimize the hyperparameters of the model.
- Not sure

### 4. You are training a machine learning model with a dataset of 10,000 samples. If you use 80% of the data for training and 20% for testing, which of the following might happen?
- The model may not have enough data to learn patterns properly.
- The model may suffer from overfitting during training.
- The test set might not fully represent the variability in the data. V
- The model’s performance on the test set might overestimate its real-world accuracy.
- Not sure

### 5. What happens when a machine learning model overfits?
- The model becomes more efficient in processing data.
- The model performs well on training data but poorly on new data. V
- The model fails to learn the patterns in the training data.
- The model performs equally well on training and test data.
- Not sure

### 6. A model achieves 95% accuracy on the training set but only 60% accuracy on the test set. What does this indicate, and how can it be resolved?
- The test set is not representative; adjust the train-test split.
- Underfitting; increase model complexity or use a larger test set.
- Balanced performance; no changes are needed.
- Overfitting; reduce model complexity or gather more training data. V
- Not sure

### 7. Why is it important to include a validation set when training a model?
- It ensures the test set remains untouched until final evaluation.
- It reduces the size of the training set, preventing overfitting.
- It simplifies the pipeline by eliminating the need for a test set.
- It allows the model to learn more patterns from the data.
- Not sure

### 8. Which of the following best describes the role of the prior probability in Bayes' Rule?
- It measures the compatibility of evidence with a hypothesis.
- It is the initial belief about an event before new evidence is considered. V
- It is the total probability of the evidence occurring.
- It represents the updated belief after considering new evidence.
- Not sure

### 9. In Bayesian classification, which of the following describes a Type I error?
- Incorrectly classifying an item as belonging to a class when it does not. V
- Failing to classify an item into a class when it belongs there.
- Miscalculating the prior probability of a class.
- Minimizing the posterior probability of an incorrect classification.
- Not sure

### 10. Spam Email Detection:
> - 90% of spam emails are correctly identified as spam
> - 10% of legitimate emails are incorrectly identified as spam
> - 40% of all emails are spam
> - 60% of all emails are legitimate

> What is the Bayes error rate for this spam filter?

- 5%
- 10% V
- 15%
- 20%
- Not sure

### 11. A company screens applicants for a job using a test. The test is designed such that:
> - 80% of qualified applicants pass the test
> - 30% of unqualified applicants pass the test
> - 60% of applicants are unqualified
> - 40% of applicants are qualified

> If an applicant passes the test, what is the probability that they are actually qualified?

- 56%
- 64% V
- 72%
- 82%
- Not sure

### 12. A factory uses a machine to sort defective items. The sorting system is imperfect:
> - P(Detected Defective|Defective) = 0.9
> - P(Not Detected Defective|Not Defective) = 0.85
> - P(Defective) = 0.05
> - P(Not Defective) = 0.95

> The cost of classifying a defective item as not defective is $10. The cost of classifying a non-defective item as defective is $5.

> Given this information, how should the system classify an item if the system detects it as defective?

- Defective
- Not Defective V
- Not sure

### 13. What is not a disadvantage of using an Artificial Neural Network?
- ANNs are not good at finding complex patterns in datasets. V
- It is difficult to figure out what made the model give a certain output.
- The training of ANNs generally requires large amounts of data.
- ANNs need a lot of computing power for training the model.
- Not sure

### 14. Given that the formula for updating weights during training is:
![image](https://github.com/user-attachments/assets/b0623b16-cb66-4516-97ff-b141f56e4143)
> What can we say about the learning rate η?

- The update of the weights are only dependent on whether the prediction is correct or wrong, not by how far is from the real expected output.
- The learning rate needs to be positive. V
- If the model predictions are 100% correct, the weights can still change.
- Not sure

### 15. Given a perceptron with weight vector [3,-1,1], bias -2, and activation function f(x) = -1 if x < 0, f(x) = 1 if x >= 0. What would the perceptron output with input vector [-1,-2,3]?
- -1
- 0
- 1 V
- 2
- Not sure

### 16. Which of the following best describes a model acting as a black box?
- In a worst case scenario, the model will still function.
- The model requires a lot of data for computing its output.
- It is hard to find out how the model came to its output.
- The model has a large memory to store data.

### 17. Assume we have a Multi-Layer Perceptron with 3 input nodes, two hidden layers of 4 nodes (h1 & h2), and an output layer of 2 nodes (out). What are the sizes of the weight matrices that can store this model?
- w_h1 = 3x1, w_h2 = 4x1, w_out = 2x1
- w_h1 = 3x4, w_h2 = 4x4, w_out = 4x2 V
- w_h1 = 4x1, w_h2 = 4x1, w_out = 2x1
- w_h1 = 3x2, w_h2 = 4x2, w_out = 4x2
- Not sure

### 18. How did you find the difficulty of the topics you learned?
- Topic 1: ML pipelines
    - Very easy
    - Easy
    - Moderate
    - Difficult
    - Very difficult
- Topic 2: Bayes' Rule
    - Very easy
    - Easy
    - Moderate
    - Difficult
    - Very difficult
- Topic 3: Perceptrons
    - Very easy
    - Easy
    - Moderate
    - Difficult
    - Very difficult

### 19. How did you find the difficulty of the test?
- Very easy
- Easy
- Moderate
- Difficult
- Very difficult

### 20. How much time did you roughly take for studying the tutorial?
- Less than 30 minutes
- Between 30 minutes and 1 hour
- Between 1 hour and 2 hours
- More than 2 hours

### 21. During the learning phase, which part did you find the most comfortable to learn/easiest to understand? Why do you think that is?
Your answer here

### 22. During the learning phase, which part did you find the most difficult to learn/hardest to understand? Why do you think that is?
Your answer here

### 23. Were there any parts or formats of the tutorials that you found particularly helpful in learning and understanding new topics? If yes, what were they?
Your answer here

### 24. If you would teach the topics to students from your own study, how would you teach them? What kind of medium would you use?
Your answer here
